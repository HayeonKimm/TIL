{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Raw Cell Format",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Lab 2-1. Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08Y0sxvtzmwJ"
      },
      "source": [
        "# Lab 2-1. Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToxF0Q2MyVkN"
      },
      "source": [
        "*   Regression: input data $x$를 output data $y$로 매핑하는 모델 $f$를 찾는것.\n",
        "\n",
        "*   Logistic Regression: 모델 $f$가 linear model의 output을 logistic function을 이용해서 0~1사이의 확률값을 예측함, 즉 $$f(\\textbf{x})=\\sigma(\\textbf{w}^T\\textbf{x}+b)=\\dfrac{1}{1+e^{-(\\textbf{w}^T\\textbf{x}+b)}}$$\n",
        "\n",
        "*   Loss function\n",
        "$$\\text{Loss}(\\textbf{w})=-\\dfrac{1}{N}\\sum y\\text{log}(f(\\textbf{x}))+(1-y)\\text{log}(1-f(\\textbf{x})) $$   \n",
        "\n",
        "*    Gradient Descent\n",
        "$$\\textbf{w}=\\textbf{w}-\\alpha \\dfrac{\\partial}{\\partial\\textbf{w}}\\text{Loss}(\\textbf{w})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvYZyVhs98ES"
      },
      "source": [
        "#### Import torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBp9D4gr90CB"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F # 학습에 관련된 함수를 담고 있음\n",
        "import torch.optim as optim # optimism에 관련된 모델. 경사하강법 등"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni6o1ZL1-DZ4"
      },
      "source": [
        "### Logistic Regression with Toy Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IZoKVr3-D24"
      },
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]] #2차원 데이터\n",
        "y_data = [[0], [0], [0], [1], [1], [1]] "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeLgb82n-JAQ"
      },
      "source": [
        "# 그대로 넣으면 int 텐서가 될텐데, 에러가 생길 수 있기 떄문에 float 텐서로 바꾼다.\n",
        "\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeopVNkB-IzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf7f5b8-9b2f-4e80-82be-2467c1b372fb"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape) # target "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 2])\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiStN1ppSksJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd0KM7lV-YyL"
      },
      "source": [
        "#### Compute the Hypothesis\n",
        "$$f(\\textbf{x})=\\sigma(\\textbf{w}^T\\textbf{x}+b)=\\dfrac{1}{1+e^{-(\\textbf{w}^T\\textbf{x}+b)}}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifdpuDHp-2V2"
      },
      "source": [
        "print('e^1 equals: ', torch.exp(torch.FloatTensor([1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToO9Lga2-6Td"
      },
      "source": [
        "W = torch.zeros((2, 1), requires_grad=True) # 인풋이 2차원이였으니까\n",
        "b = torch.zeros(1, requires_grad=True) # 아웃풋은 1차원\"\"\n",
        "\n",
        "# requires_grad = 경사하강법을 쓸 것이라면 True로 설정."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBYR28sX_JC5"
      },
      "source": [
        "hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRg6qm9Q_JC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73a2d00-9ead-40a1-aa6e-5cd3208939a2"
      },
      "source": [
        "print(hypothesis)\n",
        "print(hypothesis.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<MulBackward0>)\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXK0Hh6o_JC7"
      },
      "source": [
        "`torch.sigmoid()` 함수를 쓸 수도 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoIUrE3i_JC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de54a390-ac06-4870-c583-1580c6cf27bb"
      },
      "source": [
        "print('1/(1+e^{-1}) equals: ', torch.sigmoid(torch.FloatTensor([1])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/(1+e^{-1}) equals:  tensor([0.7311])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoAVAEWQ_JC8"
      },
      "source": [
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTrUC-kM_JC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99aca0d-a4ad-43f3-9ddf-5b7f8c1b8c79"
      },
      "source": [
        "print(hypothesis)\n",
        "print(hypothesis.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<SigmoidBackward>)\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBhMIs11_JC9"
      },
      "source": [
        "#### Computing the Loss Function (Low-level)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKtKKh3n_JC9"
      },
      "source": [
        "$$\\text{Loss}(\\textbf{w})=-\\dfrac{1}{N}\\sum y\\text{log}(f(\\textbf{x}))+(1-y)\\text{log}(1-f(\\textbf{x})) $$   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FvP_PXg_JC9"
      },
      "source": [
        " `hypothesis` and `y_train` 사이의 차이를 측정하고 싶음.\n",
        "\n",
        " : hypothesis 는 예상한 값\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daXF82d1_JC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf8b66f-5899-4436-8091-3bb3875e89ac"
      },
      "source": [
        "print(hypothesis)\n",
        "print(y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<SigmoidBackward>)\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r_BO9ZM_JC-"
      },
      "source": [
        "하나의 데이터에 대해서 다음과 같이 계산 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNwzPcpI_JC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504d26df-3806-4a4a-f86f-c1b6de093534"
      },
      "source": [
        "-(y_train[0] * torch.log(hypothesis[0]) + \n",
        "  (1 - y_train[0]) * torch.log(1 - hypothesis[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6931], grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVijn88b_JC_"
      },
      "source": [
        "전체 데이터에 대해서는 다음과 같이 간단하게 계산 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUMktKKh_JC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e56814-f9b0-4acb-9b9b-7775df6daa2b"
      },
      "source": [
        "losses = -(y_train * torch.log(hypothesis) + \n",
        "           (1 - y_train) * torch.log(1 - hypothesis))\n",
        "print(losses)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931]], grad_fn=<NegBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6ddLPwB_JC_"
      },
      "source": [
        "`.mean()` 을 사용하여 평균을 취함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpbOMfR-_JC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee1a922-4020-422e-ff13-ef16e024f671"
      },
      "source": [
        "cost = losses.mean()\n",
        "print(cost)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkMGAmgP_JDA"
      },
      "source": [
        "#### Computing the Cost Function with `F.binary_cross_entropy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM5AVk6D_JDA"
      },
      "source": [
        "실제로는 binary classification은 자주 쓰이기 때문에 pytorch에 `F.binary_cross_entropy` 라는 함수가 구현돼있음\n",
        "\n",
        "(지난번 실습의 `torch.nn.MSELoss`처럼)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km1tKeBS_JDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9094bce-ba6d-4c67-d30f-02600c6c926d"
      },
      "source": [
        "F.binary_cross_entropy(hypothesis, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lkEwRky_JDA"
      },
      "source": [
        "#### Training with Low-level Binary Cross Entropy Loss\n",
        "\n",
        "### 수기로 계산하는 버전"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmGpKdon_JDA"
      },
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq-9JTuw_JDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba65519-0cfe-4945-e983-02329c2bd64c"
      },
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((2, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n",
        "    cost = -(y_train * torch.log(hypothesis) + \n",
        "             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.693147\n",
            "Epoch  100/1000 Cost: 0.134722\n",
            "Epoch  200/1000 Cost: 0.080643\n",
            "Epoch  300/1000 Cost: 0.057900\n",
            "Epoch  400/1000 Cost: 0.045300\n",
            "Epoch  500/1000 Cost: 0.037261\n",
            "Epoch  600/1000 Cost: 0.031673\n",
            "Epoch  700/1000 Cost: 0.027556\n",
            "Epoch  800/1000 Cost: 0.024394\n",
            "Epoch  900/1000 Cost: 0.021888\n",
            "Epoch 1000/1000 Cost: 0.019852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdgFkWxY_JDB"
      },
      "source": [
        "#### Training with `F.binary_cross_entropy`\n",
        "\n",
        "### 내장함수 활용한 버전"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGDpj5xS_JDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3293dabd-b1da-4502-d311-959dce50d2ce"
      },
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((2, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.693147\n",
            "Epoch  100/1000 Cost: 0.134722\n",
            "Epoch  200/1000 Cost: 0.080643\n",
            "Epoch  300/1000 Cost: 0.057900\n",
            "Epoch  400/1000 Cost: 0.045300\n",
            "Epoch  500/1000 Cost: 0.037261\n",
            "Epoch  600/1000 Cost: 0.031672\n",
            "Epoch  700/1000 Cost: 0.027556\n",
            "Epoch  800/1000 Cost: 0.024394\n",
            "Epoch  900/1000 Cost: 0.021888\n",
            "Epoch 1000/1000 Cost: 0.019852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptwVT_adBwcD"
      },
      "source": [
        "## Logistic Regression with Real Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGn6i4npzmwP"
      },
      "source": [
        "### Load File from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HF3DXVMP66k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc079c6-b082-46d5-ece9-cb51343d5326"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoZswxPe2qFw"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THzp4Jbj2_WJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "e6c2af31-635b-4622-aa11-62ab9fd241ff"
      },
      "source": [
        "diabetes = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/diabetes.csv')\n",
        "print(diabetes.columns)\n",
        "diabetes.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
            "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWuXP-WfSlWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84b374e-04b4-414b-b59e-6f1d839e67b4"
      },
      "source": [
        "type(diabetes)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kBQn8iS3ILG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03e2363-e063-4950-d639-e3b041e6a114"
      },
      "source": [
        "print(\"dimension of diabetes data: {}\".format(diabetes.shape))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimension of diabetes data: (768, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhbQXxdWDvAf"
      },
      "source": [
        "### Split and prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R_psvxgCMmw"
      },
      "source": [
        "train = diabetes[:650]\n",
        "test = diabetes[650:]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC5Y6XJ4Cy1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1fb4e4-1924-4b1b-f4c2-f6aaf5184560"
      },
      "source": [
        "print(train.groupby('Outcome').size())"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outcome\n",
            "0    427\n",
            "1    223\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxxOmGS5C9WJ"
      },
      "source": [
        "imbalanced dataset임을 확인 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dI4nxZjCXDn"
      },
      "source": [
        "x_train = np.asarray(train.drop('Outcome',1))\n",
        "y_train = np.asarray(train['Outcome'])\n",
        "x_test = np.asarray(test.drop('Outcome',1))\n",
        "y_test = np.asarray(test['Outcome'])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKsVsvj-CuIt"
      },
      "source": [
        "input을 normalize 해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to0XDQVsDBsR"
      },
      "source": [
        "means = np.mean(x_train, axis=0)\n",
        "stds = np.std(x_train, axis=0)\n",
        "x_train = (x_train - means)/stds\n",
        "x_test = (x_test - means)/stds"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCnmDIO2Ew1g"
      },
      "source": [
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.FloatTensor(y_train).unsqueeze(-1) # 차원 하나 업그레이드 unsqueeze(-1) , tensor에 맞게 2차원으로 늘려줘야한다.\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_test = torch.FloatTensor(y_test).unsqueeze(-1)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ-JGZdhXutw",
        "outputId": "43c1f2ee-7ab9-41c4-bba4-345238cb366a"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([650, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozuh4Z3VEUAI"
      },
      "source": [
        "### Training with F.binary_cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYkE08usDNRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b687e9-681f-4ebf-ab19-ccf6295539db"
      },
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((8, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 f(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 10번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/100 Cost: 0.693147\n",
            "Epoch   10/100 Cost: 0.477473\n",
            "Epoch   20/100 Cost: 0.468751\n",
            "Epoch   30/100 Cost: 0.467308\n",
            "Epoch   40/100 Cost: 0.467003\n",
            "Epoch   50/100 Cost: 0.466932\n",
            "Epoch   60/100 Cost: 0.466914\n",
            "Epoch   70/100 Cost: 0.466910\n",
            "Epoch   80/100 Cost: 0.466909\n",
            "Epoch   90/100 Cost: 0.466908\n",
            "Epoch  100/100 Cost: 0.466908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Ji-PfWGWgY"
      },
      "source": [
        "### Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4qojW57U_DT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981d3b30-cd79-4d2b-83a9-949c54ea53b7"
      },
      "source": [
        "W, b"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.4520],\n",
              "         [ 1.0729],\n",
              "         [-0.2492],\n",
              "         [-0.0065],\n",
              "         [-0.1097],\n",
              "         [ 0.7790],\n",
              "         [ 0.3553],\n",
              "         [ 0.1201]], requires_grad=True),\n",
              " tensor([-0.9190], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCMVKeM2GhXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eea0f20-b14c-48f4-cb7b-e421f8ef4d58"
      },
      "source": [
        "hypothesis = torch.sigmoid(x_test.matmul(W) + b)\n",
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "correct_prediction = prediction.float() == y_test\n",
        "accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
        "print('The model has an accuracy of {:2.2f}% for the test set.'.format(accuracy * 100))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has an accuracy of 78.81% for the test set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il5iL00VGanK"
      },
      "source": [
        "## (Optional) Balancing the training set\n",
        "\n",
        "### 데이터 균형 맞추기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_AcaEkeEb2V"
      },
      "source": [
        "x_train = np.asarray(train.drop('Outcome',1))\n",
        "y_train = np.asarray(train['Outcome'])\n",
        "x_test = np.asarray(test.drop('Outcome',1))\n",
        "y_test = np.asarray(test['Outcome'])\n",
        "means = np.mean(x_train, axis=0)\n",
        "stds = np.std(x_train, axis=0)\n",
        "x_train = (x_train - means)/stds # 정규화 과정\n",
        "x_test = (x_test - means)/stds"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZy3OEY0HN6y"
      },
      "source": [
        "x_train_pos = x_train[y_train == 0] # 타겟 값이 0인 값\n",
        "x_train_neg = x_train[y_train == 1] # 타겟 값이 1인 값\n",
        "y_train_pos = y_train[y_train == 0]\n",
        "y_train_neg = y_train[y_train == 1]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1eZ9tJCIDzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e69341-4f1e-49b3-eddc-f267118bd01e"
      },
      "source": [
        "x_train_pos.shape, x_train_neg.shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((427, 8), (427, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhGla92yIXfX"
      },
      "source": [
        "ids = np.arange(len(x_train_neg))\n",
        "choices = np.random.choice(ids, len(x_train_pos))\n",
        "x_train_neg = x_train_neg[choices]\n",
        "y_train_neg = y_train_neg[choices]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtFyJOWZJQlL"
      },
      "source": [
        "x_train = np.concatenate([x_train_pos, x_train_neg], axis=0)\n",
        "y_train = np.concatenate([y_train_pos, y_train_neg], axis=0)\n",
        "\n",
        "order = np.arange(len(x_train))\n",
        "np.random.shuffle(order)\n",
        "x_train = x_train[order]\n",
        "y_train = y_train[order]"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7trLOiUfKCKv"
      },
      "source": [
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.FloatTensor(y_train).unsqueeze(-1)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_test = torch.FloatTensor(y_test).unsqueeze(-1)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS80UNMPKCKx"
      },
      "source": [
        "### Training with F.binary_cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P5miFc0KCKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64369eaf-781f-4ad1-a48a-71c621d42b42"
      },
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((8, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b) # or .mm or @\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 f(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 10번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/100 Cost: 0.693147\n",
            "Epoch   10/100 Cost: 0.501940\n",
            "Epoch   20/100 Cost: 0.495054\n",
            "Epoch   30/100 Cost: 0.493911\n",
            "Epoch   40/100 Cost: 0.493670\n",
            "Epoch   50/100 Cost: 0.493614\n",
            "Epoch   60/100 Cost: 0.493600\n",
            "Epoch   70/100 Cost: 0.493596\n",
            "Epoch   80/100 Cost: 0.493595\n",
            "Epoch   90/100 Cost: 0.493595\n",
            "Epoch  100/100 Cost: 0.493595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTComXX4KCKy"
      },
      "source": [
        "### Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHADwpx3KCKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12efbd7d-02d7-4f35-8a1d-5edf3c0d9f0b"
      },
      "source": [
        "hypothesis = torch.sigmoid(x_test.matmul(W) + b)\n",
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "correct_prediction = prediction.float() == y_test\n",
        "accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
        "print('The model has an accuracy of {:2.2f}% for the training set.'.format(accuracy * 100))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has an accuracy of 75.42% for the training set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aECJDSnAWys5"
      },
      "source": [
        "### 결과가 더 안 좋아졌다. 이 데이터는 데이터 밸런스가 별 영향이 없다는 뜻이다."
      ]
    }
  ]
}